<!DOCTYPE html><!--U9pkstdWHB_dyMmr_GNcY--><html lang="en" class="font-mono text-sm"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/Personal_site/_next/static/css/ef46db3751d8e999.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/Personal_site/_next/static/chunks/webpack-bd0e135f3728bc47.js"/><script src="/Personal_site/_next/static/chunks/4bd1b696-c49c6f05a40ba469.js" async=""></script><script src="/Personal_site/_next/static/chunks/964-4c57e256bb9fed16.js" async=""></script><script src="/Personal_site/_next/static/chunks/main-app-9a462457d50663ba.js" async=""></script><script src="/Personal_site/_next/static/chunks/874-437a265a67d6cfee.js" async=""></script><script src="/Personal_site/_next/static/chunks/app/page-181cdff711d2409c.js" async=""></script><title>Physical Intelligence (œÄ)</title><meta name="description" content="Physical Intelligence is bringing general-purpose AI into the physical world."/><meta name="author" content="Physical Intelligence"/><meta name="keywords" content="AI,Robotics,Physical Intelligence,Machine Learning"/><meta property="og:title" content="Physical Intelligence (œÄ)"/><meta property="og:description" content="Physical Intelligence is bringing general-purpose AI into the physical world."/><meta property="og:locale" content="en_US"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:title" content="Physical Intelligence (œÄ)"/><meta name="twitter:description" content="Physical Intelligence is bringing general-purpose AI into the physical world."/><link rel="icon" href="/Personal_site/favicon.ico" type="image/x-icon" sizes="16x16"/><script src="/Personal_site/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body><div hidden=""><!--$--><!--/$--></div><div class="p-4 md:p-12 overflow-hidden"><div class="w-full max-w-xl"><header class="flex flex-col md:flex-row justify-between items-start md:items-center mb-6 gap-4"><a class="text-3xl font-serif" href="/Personal_site/">Physical Intelligence (œÄ)</a><nav class="flex gap-4"><a class="text-link decoration-2 hover:decoration-foreground hover:text-foreground" href="/Personal_site/">Home</a><a class="text-link hover:decoration-2 hover:decoration-foreground/50 hover:text-foreground/70" href="/Personal_site/blog/">Research</a><a class="text-link hover:decoration-2 hover:decoration-foreground/50 hover:text-foreground/70" href="/Personal_site/join-us/">Join Us</a></nav></header><main><p class="mt-8 mb-8">Physical Intelligence is bringing general-purpose AI into the physical world. We are a group of engineers, scientists, roboticists, and company builders developing foundation models and learning algorithms to power the robots of today and the physically-actuated devices of the future.</p><div class="pl-2"><div class="relative flex flex-col space-y-4 border-l border-gray-300 py-4 before:h-6 before:w-px before:bg-gradient-to-t before:from-transparent before:to-background before:absolute before:-left-px before:top-0 after:h-6 after:w-px after:bg-gradient-to-b after:from-transparent after:to-background after:absolute after:-left-px after:bottom-0"><a class="flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover" href="/Personal_site/research/real-time-chunking/"><div class="flex items-baseline gap-1 justify-between text-xs w-full relative"><button class="absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2"></button><div class="flex items-baseline gap-2 relative grow truncate"><div class="font-semibold truncate" title="Real-Time Action Chunking with Large Models">Real-Time Action Chunking with Large Models</div></div><div class="text-xs text-muted-foreground whitespace-nowrap shrink-0">June 9, 2025</div></div><div class="text-xs text-muted-foreground">A real-time system for large VLAs that maintains precision and speed in the face of high latency.</div></a><a class="flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover" href="/Personal_site/research/knowledge-insulation/"><div class="flex items-baseline gap-1 justify-between text-xs w-full relative"><button class="absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2"></button><div class="flex items-baseline gap-2 relative grow truncate"><div class="font-semibold truncate" title="VLAs that Train Fast, Run Fast, and Generalize Better">VLAs that Train Fast, Run Fast, and Generalize Better</div></div><div class="text-xs text-muted-foreground whitespace-nowrap shrink-0">May 28, 2025</div></div><div class="text-xs text-muted-foreground">A method to train vision-language-action models that train quickly, maintain internet-scale knowledge, have high quality inference properties, and generalize well.</div></a><a class="flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer bg-white border border-black shadow-[3px_3px_0px_#000] hover:shadow-[5px_5px_0px_#000] transition-all" href="/Personal_site/blog/pi05/"><div class="flex items-baseline gap-1 justify-between text-xs w-full relative"><button class="absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2"></button><div class="flex items-baseline gap-2 relative grow truncate"><div class="font-semibold truncate" title="œÄ0.5: a VLA with Open-World Generalization">œÄ0.5: a VLA with Open-World Generalization</div></div><div class="text-xs text-muted-foreground whitespace-nowrap shrink-0">April 22, 2025</div></div><div class="text-xs text-muted-foreground">Our latest generalist policy, œÄ0.5, extends œÄ0 and enables open-world generalization. Our new model can control a mobile manipulator to clean up an entirely new kitchen or bedroom.</div></a><a class="flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover" href="/Personal_site/research/hirobot/"><div class="flex items-baseline gap-1 justify-between text-xs w-full relative"><button class="absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2"></button><div class="flex items-baseline gap-2 relative grow truncate"><div class="font-semibold truncate" title="Teaching Robots to Listen and Think Harder">Teaching Robots to Listen and Think Harder</div></div><div class="text-xs text-muted-foreground whitespace-nowrap shrink-0">February 26, 2025</div></div><div class="text-xs text-muted-foreground">A method for robots to think through complex tasks step by step, incorporating human-in-the-loop feedback.</div></a><a class="flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover" href="/Personal_site/blog/openpi/"><div class="flex items-baseline gap-1 justify-between text-xs w-full relative"><button class="absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2"></button><div class="flex items-baseline gap-2 relative grow truncate"><div class="font-semibold truncate" title="Open Sourcing œÄ0">Open Sourcing œÄ0</div></div><div class="text-xs text-muted-foreground whitespace-nowrap shrink-0">February 4, 2025</div></div><div class="text-xs text-muted-foreground">We are releasing the weights and code for œÄ0 as well as our new œÄ0-FAST autoregressive model.</div></a><a class="flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover" href="/Personal_site/research/fast/"><div class="flex items-baseline gap-1 justify-between text-xs w-full relative"><button class="absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2"></button><div class="flex items-baseline gap-2 relative grow truncate"><div class="font-semibold truncate" title="FAST: Efficient Robot Action Tokenization">FAST: Efficient Robot Action Tokenization</div></div><div class="text-xs text-muted-foreground whitespace-nowrap shrink-0">January 16, 2025</div></div><div class="text-xs text-muted-foreground">A new robot action tokenizer that allows us to train generalist policies 5x faster than previous models.</div></a><a class="flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer bg-white border border-black shadow-[3px_3px_0px_#000] hover:shadow-[5px_5px_0px_#000] transition-all" href="/Personal_site/blog/pi0/"><div class="flex items-baseline gap-1 justify-between text-xs w-full relative"><button class="absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2"></button><div class="flex items-baseline gap-2 relative grow truncate"><div class="font-semibold truncate" title="œÄ0: Our First Generalist Policy">œÄ0: Our First Generalist Policy</div></div><div class="text-xs text-muted-foreground whitespace-nowrap shrink-0">October 31, 2024</div></div><div class="text-xs text-muted-foreground">Our first generalist policy, œÄ0, a prototype model that combines large-scale multi-task and multi-robot data collection with a new network architecture to enable the most capable and dexterous generalist robot policy to date.</div></a></div></div><h2 class="font-bold mt-8 mb-2">Team</h2><div class="grid grid-cols-2 md:grid-cols-3 gap-y-1"><div>Ali Amin</div><div>Ashwin Balakrishna</div><div>Kevin Black</div><div>Noah Brown</div><div>Danny Driess</div><div>James Darpinian</div><div>Karan Dhabalia</div><div>Adnan Esmail</div><div>Michael Equi</div><div>Chelsea Finn</div><div>Nick Fusai</div><div>Catherine Glossop</div><div>Lachy Groom</div><div>Karol Hausman</div><div>Joey Hejna</div><div>Gashon Hussein</div><div>Brian Ichter</div><div>Szymon Jakubczak</div><div>Rowan Jen</div><div>Tim Jones</div><div>Simar Kareer</div><div>Ben Katz</div><div>Kay Ke</div><div>Marinda Lamb</div><div>Sergey Levine</div><div>Adrian Li-Bell</div><div>Mohith Mothukuri</div><div>Suraj Nair</div><div>Karl Pertsch</div><div>Allen Ren</div><div>Charvi Sharma</div><div>Lucy Shi</div><div>Laura Smith</div><div>Tobi Springenberg</div><div>Kyle Stachowicz</div><div>Alexander Swerdlow</div><div>James Tanner</div><div>Marcel Torne</div><div>Quan Vuong</div><div>Anna Walling</div><div>Homer Walke</div><div>Haohuan Wang</div><div>Lili Yu</div><div>Ury Zhilinsky</div><div>Paul Zhiyuan Zhou</div><div>...and growing!</div></div><p class="my-4">If you are interested in joining, please<!-- --> <a class="text-link hover:decoration-2" href="/Personal_site/join-us/">get in touch</a>.</p><h2 class="font-bold mt-8 mb-2">Investors</h2><p>We are grateful for<!-- --> <a href="https://www.nytimes.com/2024/11/04/business/dealbook/physical-intelligence-robot-ai.html" class="text-link hover:decoration-2" target="_blank" rel="noopener noreferrer">the support</a> <!-- -->of Bond, Jeff Bezos, Khosla Ventures, Lux Capital, OpenAI, Redpoint Ventures, Sequoia Capital, and Thrive Capital.</p><p class="my-4">You can follow us on ùïè/Twitter at<!-- --> <a href="https://twitter.com/physical_int" class="text-link hover:decoration-2" target="_blank" rel="noopener noreferrer">@physical_int</a></p></main><footer class="mt-12"><div class="max-w-3xl w-full mx-auto flex justify-between py-6 items-baseline border-t border-black"><p class="font-serif text-lg">Physical Intelligence</p><div class="flex gap-4"></div></div></footer><!--$--><!--/$--></div></div><script src="/Personal_site/_next/static/chunks/webpack-bd0e135f3728bc47.js" id="_R_" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n4:I[6874,[\"874\",\"static/chunks/874-437a265a67d6cfee.js\",\"974\",\"static/chunks/app/page-181cdff711d2409c.js\"],\"\"]\n15:I[8393,[],\"\"]\n:HL[\"/Personal_site/_next/static/css/ef46db3751d8e999.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"U9pkstdWHB-dyMmr-GNcY\",\"p\":\"/Personal_site\",\"c\":[\"\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Personal_site/_next/static/css/ef46db3751d8e999.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"className\":\"font-mono text-sm\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"p-4 md:p-12 overflow-hidden\",\"children\":[\"$\",\"div\",null,{\"className\":\"w-full max-w-xl\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]}]}]}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"header\",null,{\"className\":\"flex flex-col md:flex-row justify-between items-start md:items-center mb-6 gap-4\",\"children\":[[\"$\",\"$L4\",null,{\"href\":\"/\",\"className\":\"text-3xl font-serif\",\"children\":\"Physical Intelligence (œÄ)\"}],[\"$\",\"nav\",null,{\"className\":\"flex gap-4\",\"children\":[[\"$\",\"$L4\",null,{\"href\":\"/\",\"className\":\"text-link decoration-2 hover:decoration-foreground hover:text-foreground\",\"children\":\"Home\"}],[\"$\",\"$L4\",null,{\"href\":\"/blog\",\"className\":\"text-link hover:decoration-2 hover:decoration-foreground/50 hover:text-foreground/70\",\"children\":\"Research\"}],[\"$\",\"$L4\",null,{\"href\":\"/join-us\",\"className\":\"text-link hover:decoration-2 hover:decoration-foreground/50 hover:text-foreground/70\",\"children\":\"Join Us\"}]]}]]}],[\"$\",\"main\",null,{\"children\":[[\"$\",\"p\",null,{\"className\":\"mt-8 mb-8\",\"children\":\"Physical Intelligence is bringing general-purpose AI into the physical world. We are a group of engineers, scientists, roboticists, and company builders developing foundation models and learning algorithms to power the robots of today and the physically-actuated devices of the future.\"}],[\"$\",\"div\",null,{\"className\":\"pl-2\",\"children\":[\"$\",\"div\",null,{\"className\":\"relative flex flex-col space-y-4 border-l border-gray-300 py-4 before:h-6 before:w-px before:bg-gradient-to-t before:from-transparent before:to-background before:absolute before:-left-px before:top-0 after:h-6 after:w-px after:bg-gradient-to-b after:from-transparent after:to-background after:absolute after:-left-px after:bottom-0\",\"children\":[[\"$\",\"$L4\",\"0\",{\"href\":\"/research/real-time-chunking\",\"className\":\"flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-1 justify-between text-xs w-full relative\",\"children\":[[\"$\",\"button\",null,{\"className\":\"absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2\"}],[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-2 relative grow truncate\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-semibold truncate\",\"title\":\"Real-Time Action Chunking with Large Models\",\"children\":\"Real-Time Action Chunking with Large Models\"}]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground whitespace-nowrap shrink-0\",\"children\":\"June 9, 2025\"}]]}],\"$L5\"]}],\"$L6\",\"$L7\",\"$L8\",\"$L9\",\"$La\",\"$Lb\"]}]}],\"$Lc\",\"$Ld\",\"$Le\",\"$Lf\",\"$L10\",\"$L11\"]}],\"$L12\"],null,\"$L13\"]}],{},null,false]},null,false],\"$L14\",false]],\"m\":\"$undefined\",\"G\":[\"$15\",[]],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"16:I[9665,[],\"OutletBoundary\"]\n18:I[4911,[],\"AsyncMetadataOutlet\"]\n1a:I[9665,[],\"ViewportBoundary\"]\n1c:I[9665,[],\"MetadataBoundary\"]\n1d:\"$Sreact.suspense\"\n5:[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"A real-time system for large VLAs that maintains precision and speed in the face of high latency.\"}]\n"])</script><script>self.__next_f.push([1,"6:[\"$\",\"$L4\",\"1\",{\"href\":\"/research/knowledge-insulation\",\"className\":\"flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-1 justify-between text-xs w-full relative\",\"children\":[[\"$\",\"button\",null,{\"className\":\"absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2\"}],[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-2 relative grow truncate\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-semibold truncate\",\"title\":\"VLAs that Train Fast, Run Fast, and Generalize Better\",\"children\":\"VLAs that Train Fast, Run Fast, and Generalize Better\"}]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground whitespace-nowrap shrink-0\",\"children\":\"May 28, 2025\"}]]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"A method to train vision-language-action models that train quickly, maintain internet-scale knowledge, have high quality inference properties, and generalize well.\"}]]}]\n"])</script><script>self.__next_f.push([1,"7:[\"$\",\"$L4\",\"2\",{\"href\":\"/blog/pi05\",\"className\":\"flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer bg-white border border-black shadow-[3px_3px_0px_#000] hover:shadow-[5px_5px_0px_#000] transition-all\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-1 justify-between text-xs w-full relative\",\"children\":[[\"$\",\"button\",null,{\"className\":\"absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2\"}],[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-2 relative grow truncate\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-semibold truncate\",\"title\":\"œÄ0.5: a VLA with Open-World Generalization\",\"children\":\"œÄ0.5: a VLA with Open-World Generalization\"}]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground whitespace-nowrap shrink-0\",\"children\":\"April 22, 2025\"}]]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Our latest generalist policy, œÄ0.5, extends œÄ0 and enables open-world generalization. Our new model can control a mobile manipulator to clean up an entirely new kitchen or bedroom.\"}]]}]\n"])</script><script>self.__next_f.push([1,"8:[\"$\",\"$L4\",\"3\",{\"href\":\"/research/hirobot\",\"className\":\"flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-1 justify-between text-xs w-full relative\",\"children\":[[\"$\",\"button\",null,{\"className\":\"absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2\"}],[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-2 relative grow truncate\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-semibold truncate\",\"title\":\"Teaching Robots to Listen and Think Harder\",\"children\":\"Teaching Robots to Listen and Think Harder\"}]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground whitespace-nowrap shrink-0\",\"children\":\"February 26, 2025\"}]]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"A method for robots to think through complex tasks step by step, incorporating human-in-the-loop feedback.\"}]]}]\n"])</script><script>self.__next_f.push([1,"9:[\"$\",\"$L4\",\"4\",{\"href\":\"/blog/openpi\",\"className\":\"flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-1 justify-between text-xs w-full relative\",\"children\":[[\"$\",\"button\",null,{\"className\":\"absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2\"}],[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-2 relative grow truncate\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-semibold truncate\",\"title\":\"Open Sourcing œÄ0\",\"children\":\"Open Sourcing œÄ0\"}]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground whitespace-nowrap shrink-0\",\"children\":\"February 4, 2025\"}]]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"We are releasing the weights and code for œÄ0 as well as our new œÄ0-FAST autoregressive model.\"}]]}]\n"])</script><script>self.__next_f.push([1,"a:[\"$\",\"$L4\",\"5\",{\"href\":\"/research/fast\",\"className\":\"flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer hover:bg-background-hover\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-1 justify-between text-xs w-full relative\",\"children\":[[\"$\",\"button\",null,{\"className\":\"absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2\"}],[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-2 relative grow truncate\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-semibold truncate\",\"title\":\"FAST: Efficient Robot Action Tokenization\",\"children\":\"FAST: Efficient Robot Action Tokenization\"}]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground whitespace-nowrap shrink-0\",\"children\":\"January 16, 2025\"}]]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"A new robot action tokenizer that allows us to train generalist policies 5x faster than previous models.\"}]]}]\n"])</script><script>self.__next_f.push([1,"b:[\"$\",\"$L4\",\"6\",{\"href\":\"/blog/pi0\",\"className\":\"flex flex-col gap-1 px-3 py-2 ml-6 group cursor-pointer bg-white border border-black shadow-[3px_3px_0px_#000] hover:shadow-[5px_5px_0px_#000] transition-all\",\"children\":[[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-1 justify-between text-xs w-full relative\",\"children\":[[\"$\",\"button\",null,{\"className\":\"absolute size-[7px] bg-gray-900 rounded-sm -left-[40px] top-[4px] outline outline-background outline-2\"}],[\"$\",\"div\",null,{\"className\":\"flex items-baseline gap-2 relative grow truncate\",\"children\":[\"$\",\"div\",null,{\"className\":\"font-semibold truncate\",\"title\":\"œÄ0: Our First Generalist Policy\",\"children\":\"œÄ0: Our First Generalist Policy\"}]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground whitespace-nowrap shrink-0\",\"children\":\"October 31, 2024\"}]]}],[\"$\",\"div\",null,{\"className\":\"text-xs text-muted-foreground\",\"children\":\"Our first generalist policy, œÄ0, a prototype model that combines large-scale multi-task and multi-robot data collection with a new network architecture to enable the most capable and dexterous generalist robot policy to date.\"}]]}]\n"])</script><script>self.__next_f.push([1,"c:[\"$\",\"h2\",null,{\"className\":\"font-bold mt-8 mb-2\",\"children\":\"Team\"}]\n"])</script><script>self.__next_f.push([1,"d:[\"$\",\"div\",null,{\"className\":\"grid grid-cols-2 md:grid-cols-3 gap-y-1\",\"children\":[[\"$\",\"div\",\"0\",{\"children\":\"Ali Amin\"}],[\"$\",\"div\",\"1\",{\"children\":\"Ashwin Balakrishna\"}],[\"$\",\"div\",\"2\",{\"children\":\"Kevin Black\"}],[\"$\",\"div\",\"3\",{\"children\":\"Noah Brown\"}],[\"$\",\"div\",\"4\",{\"children\":\"Danny Driess\"}],[\"$\",\"div\",\"5\",{\"children\":\"James Darpinian\"}],[\"$\",\"div\",\"6\",{\"children\":\"Karan Dhabalia\"}],[\"$\",\"div\",\"7\",{\"children\":\"Adnan Esmail\"}],[\"$\",\"div\",\"8\",{\"children\":\"Michael Equi\"}],[\"$\",\"div\",\"9\",{\"children\":\"Chelsea Finn\"}],[\"$\",\"div\",\"10\",{\"children\":\"Nick Fusai\"}],[\"$\",\"div\",\"11\",{\"children\":\"Catherine Glossop\"}],[\"$\",\"div\",\"12\",{\"children\":\"Lachy Groom\"}],[\"$\",\"div\",\"13\",{\"children\":\"Karol Hausman\"}],[\"$\",\"div\",\"14\",{\"children\":\"Joey Hejna\"}],[\"$\",\"div\",\"15\",{\"children\":\"Gashon Hussein\"}],[\"$\",\"div\",\"16\",{\"children\":\"Brian Ichter\"}],[\"$\",\"div\",\"17\",{\"children\":\"Szymon Jakubczak\"}],[\"$\",\"div\",\"18\",{\"children\":\"Rowan Jen\"}],[\"$\",\"div\",\"19\",{\"children\":\"Tim Jones\"}],[\"$\",\"div\",\"20\",{\"children\":\"Simar Kareer\"}],[\"$\",\"div\",\"21\",{\"children\":\"Ben Katz\"}],[\"$\",\"div\",\"22\",{\"children\":\"Kay Ke\"}],[\"$\",\"div\",\"23\",{\"children\":\"Marinda Lamb\"}],[\"$\",\"div\",\"24\",{\"children\":\"Sergey Levine\"}],[\"$\",\"div\",\"25\",{\"children\":\"Adrian Li-Bell\"}],[\"$\",\"div\",\"26\",{\"children\":\"Mohith Mothukuri\"}],[\"$\",\"div\",\"27\",{\"children\":\"Suraj Nair\"}],[\"$\",\"div\",\"28\",{\"children\":\"Karl Pertsch\"}],[\"$\",\"div\",\"29\",{\"children\":\"Allen Ren\"}],[\"$\",\"div\",\"30\",{\"children\":\"Charvi Sharma\"}],[\"$\",\"div\",\"31\",{\"children\":\"Lucy Shi\"}],[\"$\",\"div\",\"32\",{\"children\":\"Laura Smith\"}],[\"$\",\"div\",\"33\",{\"children\":\"Tobi Springenberg\"}],[\"$\",\"div\",\"34\",{\"children\":\"Kyle Stachowicz\"}],[\"$\",\"div\",\"35\",{\"children\":\"Alexander Swerdlow\"}],[\"$\",\"div\",\"36\",{\"children\":\"James Tanner\"}],[\"$\",\"div\",\"37\",{\"children\":\"Marcel Torne\"}],[\"$\",\"div\",\"38\",{\"children\":\"Quan Vuong\"}],[\"$\",\"div\",\"39\",{\"children\":\"Anna Walling\"}],[\"$\",\"div\",\"40\",{\"children\":\"Homer Walke\"}],[\"$\",\"div\",\"41\",{\"children\":\"Haohuan Wang\"}],[\"$\",\"div\",\"42\",{\"children\":\"Lili Yu\"}],[\"$\",\"div\",\"43\",{\"children\":\"Ury Zhilinsky\"}],[\"$\",\"div\",\"44\",{\"children\":\"Paul Zhiyuan Zhou\"}],[\"$\",\"div\",\"45\",{\"children\":\"...and growing!\"}]]}]\n"])</script><script>self.__next_f.push([1,"e:[\"$\",\"p\",null,{\"className\":\"my-4\",\"children\":[\"If you are interested in joining, please\",\" \",[\"$\",\"$L4\",null,{\"href\":\"/join-us\",\"className\":\"text-link hover:decoration-2\",\"children\":\"get in touch\"}],\".\"]}]\nf:[\"$\",\"h2\",null,{\"className\":\"font-bold mt-8 mb-2\",\"children\":\"Investors\"}]\n10:[\"$\",\"p\",null,{\"children\":[\"We are grateful for\",\" \",[\"$\",\"a\",null,{\"href\":\"https://www.nytimes.com/2024/11/04/business/dealbook/physical-intelligence-robot-ai.html\",\"className\":\"text-link hover:decoration-2\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"the support\"}],\" \",\"of Bond, Jeff Bezos, Khosla Ventures, Lux Capital, OpenAI, Redpoint Ventures, Sequoia Capital, and Thrive Capital.\"]}]\n11:[\"$\",\"p\",null,{\"className\":\"my-4\",\"children\":[\"You can follow us on ùïè/Twitter at\",\" \",[\"$\",\"a\",null,{\"href\":\"https://twitter.com/physical_int\",\"className\":\"text-link hover:decoration-2\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":\"@physical_int\"}]]}]\n12:[\"$\",\"footer\",null,{\"className\":\"mt-12\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-3xl w-full mx-auto flex justify-between py-6 items-baseline border-t border-black\",\"children\":[[\"$\",\"p\",null,{\"className\":\"font-serif text-lg\",\"children\":\"Physical Intelligence\"}],[\"$\",\"div\",null,{\"className\":\"flex gap-4\"}]]}]}]\n13:[\"$\",\"$L16\",null,{\"children\":[\"$L17\",[\"$\",\"$L18\",null,{\"promise\":\"$@19\"}]]}]\n14:[\"$\",\"$1\",\"h\",{\"children\":[null,[[\"$\",\"$L1a\",null,{\"children\":\"$L1b\"}],null],[\"$\",\"$L1c\",null,{\"children\":[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$1d\",null,{\"fallback\":null,\"children\":\"$L1e\"}]}]}]]}]\n"])</script><script>self.__next_f.push([1,"1b:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n17:null\n"])</script><script>self.__next_f.push([1,"1f:I[8175,[],\"IconMark\"]\n"])</script><script>self.__next_f.push([1,"19:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Physical Intelligence (œÄ)\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"Physical Intelligence is bringing general-purpose AI into the physical world.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Physical Intelligence\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"AI,Robotics,Physical Intelligence,Machine Learning\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"Physical Intelligence (œÄ)\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"Physical Intelligence is bringing general-purpose AI into the physical world.\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"7\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:title\",\"content\":\"Physical Intelligence (œÄ)\"}],[\"$\",\"meta\",\"10\",{\"name\":\"twitter:description\",\"content\":\"Physical Intelligence is bringing general-purpose AI into the physical world.\"}],[\"$\",\"link\",\"11\",{\"rel\":\"icon\",\"href\":\"/Personal_site/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}],[\"$\",\"$L1f\",\"12\",{}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"1e:\"$19:metadata\"\n"])</script></body></html>